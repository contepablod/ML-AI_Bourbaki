{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_Y5C-Ng8nUr"
   },
   "source": [
    "## Machine Learning & AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Colegio Bourbaki](./Images/Bourbaki.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Fusion Transformerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hADOUUZ1SbUL",
    "outputId": "f3ebf697-8694-451d-b660-86ab1f16e7dd"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade torch pytorch-lightning pytorch-forecasting torchdata optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar la libreria pytorch-forecasting de la cual importaremos el modelo TFT. También puede utilizarse el modelo de la libreria neuralforecast de la empresa NIXTLA. Ambas se apalancan PyTorch Lightninggggg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "\n",
    "* **Pytorch Forecasting:** https://pytorch-forecasting.readthedocs.io/en/stable/index.html\n",
    "* **Neural Forecast:** https://nixtlaverse.nixtla.io/neuralforecast/docs/getting-started/introduction.html\n",
    "* **Pytorch Lightning:** https://lightning.ai/docs/pytorch/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuNPEouZ8sOW"
   },
   "source": [
    "Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRbjsfKW0R-h",
    "outputId": "91056829-5c45-4b38-cd9d-4204b83cc7a3"
   },
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch Lighting\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "# Pytorch Forcasting\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import  QuantileLoss, MAE, RMSE, SMAPE, MAPE, MASE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# Utils\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAqlusD1jDsC"
   },
   "source": [
    "No vamos a explicar nuevamente el contexto del problema, iremos directamente a la solución del problema ya planteado. La primera parte del código es similar, por lo tanto, muchas celdas no serán descriptas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m41EgD58jheH"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrpCzz1LjiW1",
    "outputId": "8bf94969-dfb8-4e8f-926b-32d1808ca75b"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zXLaLYS8v_c"
   },
   "source": [
    "Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0-RjeIZkGF0"
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('./Data/SNCF/hard/Xtrain_hgcGIrA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXexLOGBkfPR"
   },
   "outputs": [],
   "source": [
    "index = x_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJbmEclPkgw4",
    "outputId": "a1245278-4da4-4164-9328-fab118dfc79a"
   },
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpmcQYgskyjt"
   },
   "outputs": [],
   "source": [
    "df_x_train = x_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-CgnDnTk23b"
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\n",
    "    \"/home/pdconte/Desktop/Colegio_Bourbaki/ML_AI/Semana2/Data/SNCF/hard/Ytrain_yL5OjS4.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2bS5gowlI6k"
   },
   "outputs": [],
   "source": [
    "df_y_train = y_train[['p0q0']]\n",
    "df_y_train = df_y_train.set_index(index, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "qHUp2P-zn2sT",
    "outputId": "38eaa8be-dc78-43e2-855b-d91f9b96f584"
   },
   "outputs": [],
   "source": [
    "df_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yh3zspTtsN4F",
    "outputId": "d3e568a8-6a01-4e1d-85ca-9d729a2ff8f2"
   },
   "outputs": [],
   "source": [
    "df_x_train['train'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Nx-3aozBuhj",
    "outputId": "e0545816-8b38-4869-b0e0-1095c2ca36a1"
   },
   "outputs": [],
   "source": [
    "df_x_train['train'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train[\"station\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train[\"station\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVNBaEiHlNPN"
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat(\n",
    "    [\n",
    "        df_x_train,\n",
    "        df_y_train\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "j-qHpOWclw9g",
    "outputId": "af63a2a7-8d04-4a8e-e2e7-79d1bf8d64d0"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hour'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill 'hour' nan valuee with -1\n",
    "df_train['hour'] = df_train['hour'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hour'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hour'] = df_train['hour'].apply(lambda x: '10:00:00' if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hour'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"date\"] = pd.to_datetime(df_train[\"date\"], format=\"mixed\")\n",
    "df_train[\"hour\"] = pd.to_datetime(df_train[\"hour\"], format=\"%H:%M:%S\").dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of week and month as features\n",
    "df_train['day_of_week'] = df_train['date'].dt.dayofweek\n",
    "df_train['month'] = df_train['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['train'] = df_train['train'].astype(\"str\")\n",
    "df_train[\"station\"] = df_train[\"station\"].astype(\"str\")\n",
    "df_train[\"way\"] = df_train[\"way\"].astype(\"str\")\n",
    "df_train[\"composition\"] = df_train[\"composition\"].astype(\"str\")\n",
    "df_train = df_train.rename(columns={\"train\": \"train_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV09ohfjoluh"
   },
   "source": [
    "Vamos a crear una nueva columna llamada time_idx donde aisgnaremos cada fila en datos un índice basado en la posición de su valor de fecha (date) dentro dela variable de una lista (lista)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, sort the data by date and hour to ensure correct temporal ordering\n",
    "df_train = df_train.sort_values(by=[\"date\", \"hour\"]).reset_index(drop=True)\n",
    "\n",
    "# Create a unique time index within each group of (train, station)\n",
    "df_train[\"time_idx\"] = df_train.groupby([\"train_id\", \"station\"]).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El time_idx es un componente crucial a la hora de preparar datos para modelos de series temporales, especialmente en el contexto de la TFT y la biblioteca pytorch-forecasting. Sirve para varios propósitos importantes:\n",
    "\n",
    "* Orden temporal: Proporciona un índice numérico secuencial que representa el orden de los pasos temporales en los datos.\n",
    "* Alinear secuencias: Ayuda a alinear correctamente las secuencias para las partes codificadora (encoder) y decodificadora (decoder) del modelo.\n",
    "* Manejo de múltiples series temporales: Cuando se manejan múltiples series temporales (por ejemplo, diferentes trenes), asegura que los pasos temporales estén correctamente ordenados dentro de cada grupo.\n",
    "\n",
    "**¿Por qué no utilizar directamente fechas o marcas de tiempo?**\n",
    "\n",
    "Aunque las fechas y las marcas de tiempo contienen información temporal, pueden no ser adecuadas para indexar el tiempo en el modelo porque:\n",
    "* Intervalos irregulares: Las fechas pueden no estar espaciadas por igual (por ejemplo, fines de semana, días festivos), lo que puede complicar el modelado secuencial.\n",
    "* No numéricos: Los modelos requieren índices numéricos para los pasos temporales para realizar cálculos de forma eficiente.\n",
    "* Complejidad: El cálculo de diferencias temporales y la alineación de secuencias mediante fechas pueden introducir una complejidad innecesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "lVw8V86Rlo_t",
    "outputId": "757d54e5-8eeb-404f-d8a1-11f8183e8426"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucrpnKzqpL4M"
   },
   "source": [
    "Comenzaremos a utilizar Pytorch Forecasting para resolver nuestro problema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQYAvb9u3oF8"
   },
   "source": [
    "El siguiente paso es convertir el marco de datos en un PyTorch Forecasting TimeSeriesDataSet. Aparte de indicar al conjunto de datos qué características son categóricas frente a continuas y cuáles son estáticas frente a variables en el tiempo, también tenemos que decidir cómo normalizamos los datos. Aquí, normalizamos la escala de cada serie temporal por separado e indicamos que los valores son siempre positivos. Generalmente, se prefiere el EncoderNormalizer, que escala dinámicamente en cada secuencia del codificador a medida que se entrena, para evitar el sesgo look-ahead inducido por la normalización. Sin embargo, puede aceptar el sesgo de anticipación si tiene problemas para encontrar una normalización razonablemente estable, por ejemplo, porque hay muchos ceros en sus datos. O si espera una normalización más estable en la inferencia. En este último caso, se asegura de que no aprende saltos \"raros\" que no estarán presentes cuando ejecute la inferencia, entrenando así en un conjunto de datos más realista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero veamos un poco de estadisticas del time_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the range of time_idx for each train_id and station\n",
    "time_idx_stats = df_train.groupby([\"train_id\", \"station\"])[\"time_idx\"].agg([\"min\", \"max\", \"count\"])\n",
    "time_idx_stats[\"range\"] = time_idx_stats[\"max\"] - time_idx_stats[\"min\"]\n",
    "print(time_idx_stats, '\\n')\n",
    "\n",
    "# Summary statistics to see the distribution of time_idx ranges\n",
    "print(\"Time_idx range statistics across groups:\")\n",
    "print(time_idx_stats[\"range\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_idx_stats['range'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stops (unique time_idx) per train and station\n",
    "stops_per_train_station = df_train.groupby([\"train_id\", \"station\"])[\"time_idx\"].nunique()\n",
    "print(\"Stops per train-station pair:\")\n",
    "print(stops_per_train_station.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_per_train_station.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['time_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot occupancy rates over time_idx for a specific train and station\n",
    "sample_train_id = np.random.choice(df_train[\"train_id\"].unique())  # Choose an example train randomly\n",
    "sample_station = np.random.choice(df_train[\"station\"].unique())  # Choose an example station randomly\n",
    "\n",
    "sample_data = df_train[(df_train[\"train_id\"] == sample_train_id) & (df_train[\"station\"] == sample_station)]\n",
    "plt.plot(sample_data[\"time_idx\"], sample_data[\"p0q0\"], marker=\"o\")\n",
    "plt.xlabel(\"Time Index (time_idx)\")\n",
    "plt.ylabel(\"Occupancy Rate (p0q0)\")\n",
    "plt.title(f\"Occupancy Rate Over Time for Train {sample_train_id} at Station {sample_station}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones de la Exploración de Datos\n",
    "\n",
    "* Rango de time_idx (Contexto Histórico):\n",
    "\n",
    "La mayoría de las combinaciones de tren-estación tienen entre 48 y 64 pasos de tiempo (time_idx) en el conjunto de datos.\n",
    "El valor mediano (percentil 50) para el range es 57, lo que indica que la mayoría de los pares tren-estación tienen alrededor de 57 paradas.\n",
    "\n",
    "* Longitud Típica de Secuencia (Paradas por Par Tren-Estación): El promedio de paradas es aproximadamente 57, y el máximo es 65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lag columns with structural NaNs\n",
    "lag_columns = [\"p1q0\", \"p2q0\", \"p3q0\", \"p0q1\", \"p0q2\", \"p0q3\"]\n",
    "\n",
    "# Fill NaNs with -1 for these columns\n",
    "df_train[lag_columns] = df_train[lag_columns].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJDuT9QmpPyZ"
   },
   "outputs": [],
   "source": [
    "max_encoder_length = 6 \n",
    "max_prediction_length = 3\n",
    "training_cutoff = df_train[\"time_idx\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro *max_encoder_length* especifica la longitud de la secuencia de entrada (también conocida como secuencia codificadora) que el modelo utiliza para hacer predicciones. En otras palabras, determina cuántos pasos temporales pasados tendrá en cuenta el modelo a la hora de pronosticar valores futuros.\n",
    "\n",
    "En la arquitectura del Transformador de Fusión Temporal, los datos se procesan de secuencia a secuencia:\n",
    "* Codificador: Procesa los datos históricos hasta el paso temporal actual. La longitud de esta secuencia viene determinada por max_encoder_length.\n",
    "* Decodificador: Genera predicciones para futuros pasos temporales. La longitud del horizonte de predicción viene determinada por max_prediction_length.\n",
    "\n",
    "**¿Cómo afecta *max_encoder_length* al modelo?**\n",
    "* Ventana de contexto: Al establecer *max_encoder_length*, se define el tamaño de la ventana de contexto que tiene el modelo para aprender patrones a partir de datos históricos.\n",
    "* Captura de dependencias temporales: Un *max_encoder_length* mayor permite al modelo captar dependencias y tendencias a largo plazo en los datos.\n",
    "* Complejidad computacional: Aumentar *max_encoder_length* incrementa la carga computacional y el uso de memoria ya que el modelo tiene que procesar secuencias más largas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = TimeSeriesDataSet(\n",
    "    df_train[df_train[\"time_idx\"] <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"p0q0\",\n",
    "    group_ids=[\"train_id\", \"station\"],\n",
    "    static_categoricals=[\"train_id\", \"station\"],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=['time_idx', 'month', 'hour', \"way\", \"composition\", 'day_of_week'], \n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"p0q1\", \"p0q2\", \"p0q3\", \"p1q0\", \"p2q0\", \"p3q0\"], # you can pass date in YYYYMMDD format, not timestamp\n",
    "    #min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    #min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    variable_groups={},  # group of categorical variables can be treated as one variable\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"train_id\", \"station\"], transformation=\"softplus\", scale_by_group=True\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    #randomize_length=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificar tipos de variables\n",
    "* *time_varying_known_reals*: Variables conocidas de antemano (por ejemplo, características de fecha).\n",
    "* *time_varying_unknown_reals*: Variables que cambian con el tiempo pero que no se conocen de antemano (por ejemplo, variables de retardo).\n",
    "* *static_categoricals*: Variables que son constantes para una serie temporal (por ejemplo, ID del tren )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries.TimeSeriesDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time for each series\n",
    "validation_dataset = TimeSeriesDataSet.from_dataset(\n",
    "    training_dataset, \n",
    "    df_train, \n",
    "    predict=True, \n",
    "    stop_randomization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders for model\n",
    "batch_size = 64\n",
    "train_dataloader = training_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=6)\n",
    "val_dataloader = validation_dataset.to_dataloader(train=False, batch_size=batch_size, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9UDucwypXyb"
   },
   "source": [
    "Aquí estamos configurando un conjunto de datos para entrenar y validar un modelo de series temporales utilizando la biblioteca pytorch-forecasting, que es popular para tareas de predicción en series temporales con PyTorch.\n",
    "\n",
    "A continuación, se detalla paso a paso lo que se está realizando:\n",
    "\n",
    "  * Definición de Parámetros: Se establecen dos parámetros, max_prediction_length y max_encoder_length, que definen respectivamente la longitud máxima de la predicción y la longitud máxima del codificador (historia o contexto utilizado para la predicción).\n",
    "\n",
    "  * Cálculo del Punto de Corte para el Entrenamiento: Se calcula training_cutoff para determinar hasta qué punto en el tiempo se incluirán los datos en el conjunto de entrenamiento. Esto se hace para asegurar que haya suficientes datos hacia el final del conjunto de datos para validar el modelo.\n",
    "\n",
    "  * Creación del Conjunto de Datos para Entrenamiento (TimeSeriesDataSet):\n",
    "      Se filtran los datos para incluir solo aquellos puntos en el tiempo que son iguales o anteriores al training_cutoff.\n",
    "      Se especifican varias configuraciones importantes para el conjunto de datos, como los índices de tiempo (time_idx), la variable objetivo (target), los identificadores de grupo (group_ids), las longitudes mínima y máxima del codificador, y la longitud de la predicción.\n",
    "      Se definen configuraciones adicionales como categorías estáticas y reales, variables conocidas y desconocidas tanto categóricas como reales, y se establece un normalizador de grupo para la variable objetivo.\n",
    "      Se añaden características adicionales como el índice de tiempo relativo, las escalas del objetivo y la longitud del codificador.\n",
    "\n",
    "  * Creación del Conjunto de Datos para Validación (TimeSeriesDataSet.from_dataset):\n",
    "      Se crea un conjunto de datos para validación a partir del conjunto de entrenamiento, utilizando la totalidad de los datos pero configurando el conjunto para predecir los últimos max_prediction_length puntos para cada serie temporal.\n",
    "      Esto permite evaluar cómo el modelo predice los datos \"futuros\" basándose en el conocimiento \"pasado\".\n",
    "\n",
    "  * Creación de DataLoader para Entrenamiento y Validación:\n",
    "      Se crean DataLoader para ambos conjuntos, permitiendo la carga eficiente de datos durante el entrenamiento y la validación del modelo en mini-lotes de tamaño batch_size.\n",
    "\n",
    "Este proceso es típico en la preparación de datos para el entrenamiento de modelos de series temporales, permitiendo un manejo eficiente de diferentes longitudes de series, incorporación de variables explicativas y ajuste de parámetros específicos para la predicción temporal. La biblioteca pytorch-forecasting facilita la manipulación de series temporales complejas y la implementación de modelos de deep learning para su predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQlRqMiu5gQq"
   },
   "source": [
    "Para determinar el valor adecuado de max_prediction_length para tu conjunto de datos, debes considerar el objetivo de tu análisis de series temporales y la naturaleza de los datos. El valor de max_prediction_length no se deriva directamente de los datos en sí, sino que es una elección que depende de cuánto en el futuro deseas predecir basado en la estructura temporal de tu conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grY5PGcxp2QD"
   },
   "source": [
    "Ahora, pasaremos al modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__ycFewLx4dH"
   },
   "source": [
    "Vamos a calcular un benckmark base al cual deberíamos superar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFtNE_Qgqh01",
    "outputId": "e0b6da5c-f6f5-47e4-f335-81abf04c4724"
   },
   "outputs": [],
   "source": [
    "# calculate baseline errors, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(train_dataloader)])\n",
    "baseline_predictions = Baseline().predict(train_dataloader, return_y=False, mode='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_baseline_predictions = MAE()(baseline_predictions.cpu(), actuals)\n",
    "mape_baseline_predictions = MAPE()(baseline_predictions.cpu(), actuals)\n",
    "smape_baseline_predictions = SMAPE()(baseline_predictions.cpu(), actuals)\n",
    "rmse_baseline_predictions = RMSE()(baseline_predictions.cpu(), actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QULHivnEbfUe",
    "outputId": "b0ade0a1-0db4-4f34-fa04-38c5f5411524"
   },
   "outputs": [],
   "source": [
    "# Print baseline errors\n",
    "print(\"MAE:\", mae_baseline_predictions.item())\n",
    "print(\"MAPE:\", mape_baseline_predictions.item())\n",
    "print(\"SMAPE:\", smape_baseline_predictions.item())\n",
    "print(\"RMSE:\", rmse_baseline_predictions.item())\n",
    "print(\"MSE:\", (rmse_baseline_predictions.item())**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1ADwyLVvdc9"
   },
   "source": [
    "**Temporal Fusion Transformers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P51M9CoFvjIl"
   },
   "source": [
    "Las previsiones multihorizonte a menudo contienen una compleja mezcla de variables de entrada - incluidas covariables estáticas (es decir, invariables en el tiempo), variables de entrada futuras conocidas y otras series temporales exógenas que solo se observan en el pasado - sin ninguna información previa sobre cómo interactúan con el objetivo. Se han propuesto varios métodos de aprendizaje profundo, pero suelen ser modelos de \"caja negra\" que no arrojan luz sobre cómo utilizan toda la gama de entradas presentes en escenarios prácticos.\n",
    "\n",
    "El Transformador de Fusión Temporal (TFT), una arquitectura basada en la atención que combina la previsión multihorizonte de alto rendimiento con una visión interpretable de la dinámica temporal.\n",
    "\n",
    "Para aprender las relaciones temporales a diferentes escalas, el TFT utiliza capas recurrentes para el procesamiento local y capas interpretables de autoatención para las dependencias a largo plazo.\n",
    "\n",
    "TFT utiliza componentes especializados para seleccionar las características relevantes y una serie de capas de compuerta para suprimir los componentes innecesarios, lo que permite un alto rendimiento en una amplia gama de escenarios.\n",
    "\n",
    "* Link: Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting - https://arxiv.org/pdf/1912.09363.pdf\n",
    "* Link: https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.models.temporal_fusion_transformer.TemporalFusionTransformer.html#pytorch_forecasting.models.temporal_fusion_transformer.TemporalFusionTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nX2vy35IyMAk"
   },
   "source": [
    "Instanciamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNez1MGCqrwa",
    "outputId": "66d043c9-df6b-42a3-8a36-4945aea25466"
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", #cpu\n",
    "    devices=1,\n",
    "    gradient_clip_val=0.1, # clipping gradients is a hyperparameter and important to prevent divergance of the gradient for recurrent neural networks\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training_dataset,  \n",
    "    learning_rate=0.03, # not meaningful for finding the learning rate but otherwise very important\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    attention_head_size=1,  # number of attention heads. Set to up to 4 for large datasets\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    reduce_on_plateau_patience=4, # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prZMtm7Iqv2z",
    "outputId": "7b9b5031-85c8-4f21-fb1a-82957bcf1ecf"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225,
     "referenced_widgets": [
      "047ca1c89a784fe9b0ebb22bf12ebe70",
      "67a0bfd87fc4412c99aec3a2062b57aa",
      "5a224f8e86c44ea48cef4e4b49c29860",
      "18b79c40daa043af867431f814da4e9e",
      "8e23974df1e84602b07ce92d61ea0001",
      "b2c0ef8259c24b5d8e96479bbde74244",
      "36e76d41ab6b492f9b6455af5f872f69",
      "5c7d75a912194d17a4cf2f06fde27673",
      "28e8f6bcde5c47c59f9da2fd6bfd1559",
      "67268cae4891478295a3e4f18aaf0ae2",
      "8b4f9915a4354b7b8c48fbc470e74245"
     ]
    },
    "id": "0bJmYRDZq0n1",
    "outputId": "0ce5c045-2d85-4c3e-ed58-41cf35b8a9b6"
   },
   "outputs": [],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=1,\n",
    "    min_lr=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "K0RUpaMyq2LM",
    "outputId": "926f7fea-3913-4f3e-d1d6-c26873a6a613"
   },
   "outputs": [],
   "source": [
    "print(f\"Suggested Learning Rate: {res.suggestion()}\")\n",
    "res.plot(show=True, suggest=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pWxytWbyuJy"
   },
   "source": [
    "Para el TemporalFusionTransformer, la tasa de aprendizaje óptima es diferente a la sugerida.\n",
    "\n",
    "A veces, no queremos utilizar directamente la tasa de aprendizaje sugerida porque PyTorch Lightning a veces puede confundirse por el ruido a tasas de aprendizaje más bajas y sugiere tasas demasiado bajas.\n",
    "\n",
    "El control manual es esencial.\n",
    "\n",
    "De todas maneras la tasa calculada se encuentra de valores conocidos, por lo tanto la usaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwXuLHsUzKaG"
   },
   "outputs": [],
   "source": [
    "LR = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPgrQZHcs0H9",
    "outputId": "a2953d9c-c56c-4941-f92a-b3ff27d3ea6a"
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training_dataset,\n",
    "    learning_rate=LR,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='gpu',   #Descomentar si hay GPU disponible\n",
    "    devices=1,           #Descomentar si hay GPU disponible\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=1,\n",
    "    #limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    #fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idCt7IoUu5ev",
    "outputId": "5c06e474-c294-45e5-9b35-11746fa37048"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e1d68cf6c04d444fa64cc269b6f57164",
      "06dc0415c9c74a399ae71d84a967a6ef",
      "e465695223034b0380cbee8694bcc502",
      "14f974490d8340c3b96f7b877cefb1ae",
      "481ab2c05d614de98042e40d166f2f44",
      "d7aada4396d84240addcb7e356574e38",
      "1bfd001f474243a2840ae35de9887295",
      "6c130859918d4cc59f2d8de792e88a0d",
      "09d9ae4bc7b84407b5bb9fe3b0416ffc",
      "50c83be4209344a4af894304d061c496",
      "8cc555bf4950494e91bde6dd1cb1f86b",
      "3f290b5deac54e73aeadbab0eecaf521",
      "a6ef7a4153054be99b534e36acff66e5",
      "f3d607f6e4324cc0b65cac1f121054a3",
      "c687bd400b7041cc92e5a86d07e1be12",
      "5d95eebce68c4dee8c57fab6e5bd0e9c",
      "53bc3ee1f79c42598b46af41533baac2",
      "758c1bea16934cc7b1c66cddf2131824",
      "cf70d9aca74046a5a34b5cba21fc9cde",
      "8ab8b9a2cfd04c94b9f3503151e966e5",
      "66852b1f32224a9197a36e165df39eed",
      "b191fb0fb442461e8019d4376fd3fde5",
      "148c33c6c6af4491a0f1fce41573111d",
      "b8743e6346f845cda0b097828c7504c1",
      "dfef82c9ea2340d4924c86bc94eb38b2",
      "9f2a5e4f423a42c7985afbf4a6eab656",
      "a4a56a73db7d45de8958f81e3fd8879e",
      "13211ae9842b4c6a9ee6ba8c79a6550d",
      "9b20a02c5eb54c768e00b426b7294a4e",
      "8e2ea8bad43544aaa89f5e13c6b974e2",
      "c5e7caad2d99436dbc7cddc8de5d7092",
      "f4c7aa9553664444807adb1d75c3dfb8",
      "0c242008b6b345d5a01bd26b072d025d",
      "ec77bd8902d94fe2bd5a77c6d45b1ebf",
      "eab41bd5d3b14b78a12151a23835d08c",
      "ac9ff202408f4ad4b6ef6ea843e9956a",
      "21d9da516be747fb8b1e3d128f16942b",
      "5a36c969f92a4bf3904618fe83188146",
      "71855ab5f2784967b556c6980c7d07e7",
      "c455a13169344f2e91b3fba48909d73c",
      "8b9c7f9864e94cc18de060580eacce78",
      "f23b5188887c4279897bf82f0fde0859",
      "52877b89b8344b5ba830e6301d4fab14",
      "331c24fc05e2422783611b3f9ba9cfce",
      "c17c9ae4e3a94271856076b7bc7db4c4",
      "415188ee8ee5426e8ebb0aba54338f91",
      "a4fbb15189ca450aa273ebe158c3f1d8",
      "76b6522c64dd45e0b056ed3500db7fb4",
      "bf2e8cdfaf384880baba2abfa811975b",
      "8a6633e0364f47d6a13119d664b3d389",
      "3f9004d11a564b309ec99f52c8abba07",
      "47a09a68e1884fd1a54192c67df8c44f",
      "e2c045faf71e47c8b57cf804c142090d",
      "6ddfa261d7c740e78a83ea99f73309ef",
      "368e66c261d447bd8e235b2701f82720",
      "3ef28966147b48888b2c8464906674a2",
      "ff9764285ba24ab5bbb81db9fc94bc2f",
      "26f99bd305474620b13b497745e17c8b",
      "26bc43fee2ca410a9c2b9db023ac2661",
      "e782e7b895f447e1ab208e7fba90ace4",
      "3c08ef34ca0142c4b9b17fd100c04a11",
      "0d56e314826d43bebcad2ecec949c2e1",
      "b7b63779816d4d46a4e9af57cf81c407",
      "2bdaee8cd3c5423b9f4a99418e06a340",
      "b3b186e72545473bbaeb9ce4d544ac31",
      "57437a90211147c69ef0230b9a04b7c2",
      "cf7d2de8de3d47ca8d3920b9a67ab78f",
      "e4551d8983a5439bbbca47eff81281fc",
      "d4515abc24ec4ceda4e42049b4ae58c5",
      "dfa7d86f8c14442baaa781f350afd04c",
      "8ac3e741a0e44213aae7d1e7465d6ffd",
      "33378b856c9e450b9e2b4c89913084c8",
      "fe1a8ad4cb544b4bb26fc827c3433f51",
      "a5363c5a5a094f98b9931db59ec1c91d",
      "c5179310492849a99862cfff8518de60",
      "26d99ac5596c40e3bd284f44504b77d4",
      "6671525eede44627b131829c64a972eb",
      "6bb61f5dc9f246868a451f9ca69c8b06",
      "259c62cc1e114f809a3b0606da834611",
      "a00777139a7f4190b28d0f01f693bf3e",
      "070cbded1a7941d5bf31910e4c0c1707",
      "c1c87b8140d84c4fb2cd0bc80f5b69ae",
      "b823cd4868584d22b5194f1dbd993714",
      "e45842485ffe40f8a4697dfee43183f1",
      "660196f2865a47cd918fe3a4c756a81b",
      "df771056c0a5468a957872a9528b7e78",
      "f35c559d60ef41439903358f9418c254",
      "5c657c91e6a64e14909430c612724c9b",
      "51ce096b1b924d4a97f2486f1ea803f8",
      "1d88d8912d6445668d2aa67e3b798e1b",
      "271a145dd08e4eec97197e2b1ce573b2",
      "2195c8efafa347f8acd847932f734802",
      "6c85f69310ab4e5b8baa1997b75c9d0c",
      "451bccf89b5b48be923c3fd40a73cfd2",
      "55ff46380fdc4fa2ab6d7fce79e6b255",
      "c648757cb0c24cc1884a4d8ef6110fbc",
      "48d99e1e403b476c8dd5ca39a0ff81b0",
      "d6e4809a40144287b031fba6b1d524bc",
      "cc6cf51f74ab4c01b1a91db4e3f2520f",
      "084c5fe6728e45f2896176bfc5008e72",
      "ac81dc82707e4cc4a20e244822d72449",
      "dd4385db9d984e1ab9b98bd3783e186f",
      "f0b92c4e24b04365b6ec47979692a762",
      "de862cebf3114c47b6aca0128f4578d9",
      "43929d2817c8434eb5e1a018753d0445",
      "bf88ea92671e4acfa5e2f3573c2077a7",
      "ea6df1343fcb42cb896ec83fc9abfcb2",
      "7eb292d61f864ea9ac058c79a142804b",
      "4c595ad2e34b4f2b95f818f4ad701c3d",
      "bbbfe122a0984887851ec084cdeb9368",
      "2da1aae421f049208affb482939555e7",
      "f02d745331bb4a0bbad0c9d7b0e5fe2d",
      "a37688888ba345829534d150174c02ba",
      "a53bccb17cfb453eaaa68bd07ebf70d9",
      "bec2792ded884b6ba8b6b414d12af72f",
      "bd243a69befb4956a2285635f68a07ee",
      "8564fbda3d284fb1904514e7de73edbc",
      "bd5754d0836c466099d1cc9dd75c46fb",
      "9f9f18299d214a45a92aeb8fad63e9f6",
      "3c3184f0eb30445ca35023e7bb3f65c8",
      "66ad869b68b6441c8f1700d642236f79",
      "70250998046349e8b81c17b784550ef3",
      "634505d7dc2949e484594630824388fc",
      "4de916a7565043f99faee591a2ad23c1",
      "fb7483302b584c859432c366ab76d230",
      "3b0364df28944114b3f1e709e085c15f",
      "b6eff8c98e8d42928331e35b2a3d16df",
      "4bd464bdc4e0424eac8b5725a68bab1f",
      "345a132c5518420d86b60a6b342f9743",
      "88225a41cf4945d687522bee917c15bb",
      "2c06b0d8fc144469bf88a45b42c9d470",
      "80f88b58064e4e44b75542349a7e7cb2",
      "3c5a201d16b24ff6a703929b942a1237",
      "2108eb29667e44b6b32cb4edb80b4f63",
      "360206eea5f743f293d9f92b87d8de7e",
      "18940d86504f4ea8836685ee03bdc20a",
      "31c92e252b354427afe5084786988781",
      "846495de6e9243bd9dbf7229ca7c25d7",
      "f4065424eeb24f5fa641c9ef6b049ab9",
      "67806c19962d45739b3a35669b383ed8",
      "aebb8cfff6644e2eb8928dc51547a6c0",
      "0c8f2e89e073418b9680e4a1565cbf1b",
      "b1edfb7a13c74b40b77d96e44d064ed5",
      "236950b210a3459596985d866f0d0ef1",
      "4979de4a922d48e39485a2d61ecd525e",
      "21f74ad8ca9d43e188005a2481b3aa97",
      "4c1b52044afc42e3afaea080c8a64ce7",
      "56b7dc00aa224753bf609dcdfa2d8b1c",
      "4b36da49fd244cc8b80dc734267d71e2",
      "ba4530e3ea924eeca0239c21fb1b4f82",
      "9b8e3db241a5417c871cf9f532a89bf1",
      "352a7f33193c42649bd66c323bcae1d1",
      "d5a53fbad9b44b31aa8fdb40f60631d4",
      "2b33eadfe49f4dcd95052d340ada5235",
      "d710096ef5ae4adf8c8bfbb6161a45a6",
      "ec39c5dc6f67480db6b442b2abf2a179",
      "dfd072c47d2840649bc4e0cedc1916a7",
      "aca400dfc5294fd880fe7691b89bc4eb",
      "91b852e348544a648301a5fe03799e4e",
      "85e3f27cefa94fbf8f05f1025867135f",
      "6988b0e47ef04d8a8ee26bdaea3fe709",
      "f542e69573d142e289e99f2868da9ec0",
      "d0c90257d5fc4fc78c9394d737f39b4c",
      "27e45c9ffa56425b8865fe20989dfdb8",
      "2f11fef9084b49129169790dd4521f88",
      "cc823f59ad164cac8ddb01db86446e8c",
      "83b5d90d3eeb4e618177ac257416f0e7",
      "ee72865d98854ab187b2857e4b37b153",
      "a08a113d5d934850aeeb20e3b4e4fa40",
      "6a809b9d86f24fb0bd9fe039225bee87",
      "44f3479a90b74dda8488de3e045f84cf",
      "d7ea4d2535064f139b630e754720c4c9",
      "57cb9d73630c4e61bc91b8dbfdee2472",
      "f1459d83b207420aa7d246b51ff34e66",
      "e182d74559de47c7b13350a9db67c5e5",
      "69e48d8f155841c1a67e76a2d36d2370",
      "edaf41c991b848cab173fd340e039cd8",
      "82a31aacd821467aadf464bae339caaa",
      "e5fa128fa5e545c3a61fec26ddae1c9a",
      "6d9b780da3ca439f80a20a3047a5e942",
      "beb47fff752143e1ba412d0afbb80ae3",
      "36232b6f7294480091e660f8ced5d2bf",
      "9b6a954a66824a21a30b1e4412bace7b",
      "8ed4f748a101423d9cd9a939a3909181",
      "ad8aa5b2c31143d79682427711212044",
      "a2e6b6dabed24c358da97078eb247ecd",
      "3cf29b79c10e4542a1da012469702dfa",
      "ff5ce29f020e493f8759ea61ced39554",
      "e479f6eb425f4512bfd5659636eb915b",
      "f90e3b216f7448d3b9e38c64db4dfb87",
      "c975234ecfe14874991dce1f4b3a5fc2",
      "0f20f588626544ebb9b2ef3c78323107",
      "00cf854541764f2eb417c4bf44d6a732",
      "6b9ef14184824230a7b0372f5da5ddc8",
      "987be98ad8ad47bfbe2cdc53deae25c2",
      "2d729dde0195433a82489dbcd16c6252",
      "9cc3053f32694febb116f39cb9fa7c8f",
      "5c29b530c5204232b9f774d272a5a288",
      "25d88908281e4869a24d0923356ffe84",
      "0d213242f33343a483592e94361a7894",
      "79f6c6c8dd414565b52fc27a2461e552",
      "ea864a890992495aa5b7f6896fea0a04",
      "1fee347a1e70447da865b825bcfe291c",
      "33d8a426efa74deaad639d591c0690cf",
      "e6f7334d18934b97a1ef7fc11eaffbaa",
      "57b2cba79484431899b2297aa1d67957",
      "1ba7e4c245d24b88ac55c5ed1f837345",
      "e2b31006f9b44a95bbd5d8314fc3024b",
      "f8397759967d43acadab294ffb6629ac",
      "fca96441186c4f5d8ed0d2363655e443",
      "623981d635cd46aa82763b1a147ba328",
      "5827430e3a4745978e494a95432bd450",
      "e4a751cf44a940219de2b8e14c3f0b6b",
      "334c070688374111aaf9046a442291a6",
      "30c96fff1de84bf7ae4b42f39ced5fb2",
      "a01bf0a3bf7b476a8d5609d8db78c69e",
      "b5b70fd387c04af1880971572e66e3f2",
      "7a1a25c3bd4e41b2bbe9b4acaeaca719",
      "47b18a7ce6944d47a1e943d515fc1253",
      "ce0ec7ec4f6946568e04e0c4db2b9a48",
      "52839798af114d0eb7f7d282756135dd",
      "10312c638d1e4a66b50dab62032a4014",
      "6fe2425c1de04c59aff9d8d827a1723c",
      "1df11d58ebe24abd978f47470ef9fa28",
      "3db7e20921f24a47a239ef2262bb52b3",
      "41e3f79a27d145149dd06d9fd6db83b6",
      "4b49bbdc8755452dadc67465ced5d980",
      "4ac1594fe7734cf798b05807be305024",
      "864f75ad6df148fca028ab66d8aa0c6f",
      "59a59783b1824cce9ff4ea6ebd016dbf",
      "16b1065da6f04271a534adeb89d1f680",
      "b7a906ce5a0f4a91b7c1b4c5392cd41c",
      "f63bd082007e4f62ab79b6bb74526534",
      "a4249334a0934743a4d715dfe2789cd3",
      "570a05f1880c4abea40e52e4e204f070",
      "e5c45facea9a490ea29715cf0ed3c276",
      "c8015cf985e94de19d5fb69c0fa2c0fa",
      "1e63402508f049d79509c4188439a5be",
      "cd593203623c42819cc49bc53b88c3ce",
      "7c17afead34042828756c0e9c7206fb9",
      "5829f5d89dcb4a86889c80c4260d85cc",
      "4444d6d39e72472c8f8a59ae76c9f8b9"
     ]
    },
    "id": "CyquWTBPvU1X",
    "outputId": "7dd1141c-ab4e-4fe7-b196-5c9127162bcc"
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRQnHTntzq9O"
   },
   "source": [
    "Vamos a realizar un fine-tuning de hiperparámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optuna** es una biblioteca de optimización de hiperparámetros basada en Python diseñada para ser eficiente y flexible. Es particularmente útil en proyectos de machine learning, donde encontrar los mejores hiperparámetros puede ser una tarea compleja y costosa en cuanto a tiempo y recursos.\n",
    "\n",
    "**Características principales:**\n",
    "\n",
    "1) Optimización automatizada de hiperparámetros: Optuna permite realizar la búsqueda de hiperparámetros de forma automática y eficiente mediante estrategias de optimización como Tree-structured Parzen Estimator (TPE) y Sequential Halving.\n",
    "\n",
    "2) Definición de búsqueda sencilla: En Optuna, la búsqueda se estructura en trials (pruebas), y se define una función objetivo que representa la métrica que queremos optimizar (por ejemplo, la precisión o el error de un modelo). Optuna ejecutará esta función varias veces, ajustando los hiperparámetros cada vez.\n",
    "\n",
    "3) Exploración y explotación inteligente: Usa métodos avanzados que balancean entre probar nuevas configuraciones de hiperparámetros (exploración) y refinar configuraciones prometedoras (explotación), lo que reduce el tiempo y el costo computacional.\n",
    "\n",
    "4) Soporte para paralelización y multihilo: La biblioteca es compatible con la ejecución de búsquedas en paralelo, lo que permite realizar múltiples pruebas simultáneamente en configuraciones de varios núcleos o en un clúster, mejorando la eficiencia en grandes proyectos.\n",
    "\n",
    "5) Optimización distribuida: Para proyectos a gran escala, Optuna permite realizar búsquedas distribuidas, lo que facilita su integración en infraestructuras de computación en la nube o sistemas distribuidos.\n",
    "\n",
    "6) Visualización y seguimiento: Optuna incluye herramientas de visualización para analizar el rendimiento de los trials y entender la convergencia de la optimización. Esto es útil para identificar patrones o configuraciones de hiperparámetros que producen buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2aKwsUWg1fu",
    "outputId": "e3cc5d04-9537-465d-c169-93f8b75815a8"
   },
   "outputs": [],
   "source": [
    "# create study for hyperameter optimization\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=1,\n",
    "    max_epochs=1,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.0001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    #trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\n",
    "    \"/home/pdconte/Desktop/Colegio_Bourbaki/ML_AI/Semana2/Data/Model/ModelDatatest_study.pkl\",\n",
    "    \"wb\",\n",
    ") as fout:\n",
    "    pickle.dump(study, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kGcBEdT0KKz"
   },
   "source": [
    "Veamos cuales son los hiperparámetros óptimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qHhHeHshNkY",
    "outputId": "b4966560-8c71-429d-d50f-d96955050922"
   },
   "outputs": [],
   "source": [
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ln3m1ODBjkBf"
   },
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgJ7Bkkojs1V",
    "outputId": "b8ea4b61-9178-428a-a904-345723e8e8ab"
   },
   "outputs": [],
   "source": [
    "# calculate mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_predictions = MAE()(predictions.cpu(), actuals)\n",
    "mape_predictions = MAPE()(predictions.cpu(), actuals)\n",
    "smape_predictions = SMAPE()(predictions.cpu(), actuals)\n",
    "rmse_predictions = RMSE()(predictions.cpu(), actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ofcraEP0XCk",
    "outputId": "dd1856f3-f7e8-4cc2-ae03-94ccb745b792"
   },
   "outputs": [],
   "source": [
    "#Print mae, mape, smape, rmse errors\n",
    "print(f'MAE: {mae_predictions}')\n",
    "print(f'MAPE: {mape_predictions}')\n",
    "print(f'SMAPE: {smape_predictions}')\n",
    "print(f'RMSE: {rmse_predictions}')\n",
    "print(f'MSE: {(rmse_predictions)**2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparemos con el baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print baseline errors\n",
    "print(\"MAE:\", mae_baseline_predictions.item())\n",
    "print(\"MAPE:\", mape_baseline_predictions.item())\n",
    "print(\"SMAPE:\", smape_baseline_predictions.item())\n",
    "print(\"RMSE:\", rmse_baseline_predictions.item())\n",
    "print(\"MSE:\", (rmse_baseline_predictions.item())**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktjwKf1p0gyd"
   },
   "source": [
    "Vamos a realizar predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W66-W40H2AiE"
   },
   "source": [
    "Después del entrenamiento, podemos hacer predicciones con predict(). El método permite un control muy fino sobre lo que devuelve, de modo que, por ejemplo, puede hacer coincidir fácilmente las predicciones con su marco de datos de pandas. Evaluamos las métricas en el conjunto de datos de validación y en un par de ejemplos para ver lo bien que funciona el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtUlFS4gbwtE",
    "outputId": "38fae5ef-4aa3-422c-b228-2f2474a887a9"
   },
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AOhxcm5peO4o",
    "outputId": "3925023d-0c65-4e2f-ea46-ba6b321522b3"
   },
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(raw_predictions.x, raw_predictions.output, idx=idx, add_loss_to_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3zrKS5j2m4T"
   },
   "source": [
    "Comprobar cómo se comporta el modelo en distintos segmentos de datos nos permite detectar puntos débiles. Ahora podemos predecir directamente sobre los datos generados utilizando los métodos calculate_prediction_actual_by_variable() y plot_prediction_actual_by_variable(). Las barras grises denotan la frecuencia de la variable por bin, es decir, son un histograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dhn_mK0cknx9",
    "outputId": "d52edad1-a527-4be7-ded0-a3b8598e538c"
   },
   "outputs": [],
   "source": [
    "predictions = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(predictions.x, predictions.output)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hIjcEBQVk_qY",
    "outputId": "a67076ad-05ec-4cdd-d960-5b57bb327df0"
   },
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions.output, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume raw_predictions has an `encoder_attention` key\n",
    "encoder_attention = raw_predictions.output.encoder_attention  # Shape should be (batch_size, max_encoder_length, num_attention_heads)\n",
    "\n",
    "# Average across the batch and attention heads dimensions\n",
    "mean_encoder_attention_over_time = encoder_attention.mean(dim=(0, 2)).detach().cpu().numpy()\n",
    "\n",
    "# Create an array for time steps (assuming max_encoder_length is the length of time steps)\n",
    "time_steps = np.arange(mean_encoder_attention_over_time.shape[0])\n",
    "\n",
    "# Plot encoder attention over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_steps, mean_encoder_attention_over_time, label=\"Encoder Attention\")\n",
    "plt.xlabel(\"Time Steps (Past Time Indices)\")\n",
    "plt.ylabel(\"Mean Attention Score\")\n",
    "plt.title(\"Past Variable Importance Over Time (Using Encoder Attention as Proxy)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio:\n",
    "\n",
    "* Realizar predicciones con el modelo entrenado.\n",
    "* Utilizar la libreria `neuralforecast` de Nixtla para entrenar un nuevo modelo. Inspeccionar sus utilidades.\n",
    "\n",
    "Link: https://nixtlaverse.nixtla.io/neuralforecast/docs/tutorials/forecasting_tft.html#forecasting-with-tft-temporal-fusion-transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSKKNf0j2N5y"
   },
   "source": [
    "* Introducing PyTorch Forecasting: https://towardsdatascience.com/introducing-pytorch-forecasting-64de99b9ef46\n",
    "\n",
    "* Demand forecasting with the Temporal Fusion Transformer: https://pytorch-forecasting.readthedocs.io/en/stable/tutorials/stallion.html#Hyperparameter-tuning\n",
    "\n",
    "* Building Custom Models: https://pytorch-forecasting.readthedocs.io/en/stable/tutorials/building.html#passing-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lenguaje Matemático](./Images/Matematicas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contacto](./Images/Contacto.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
